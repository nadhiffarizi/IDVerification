{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6cadac",
   "metadata": {},
   "source": [
    "## Objective\n",
    "1. detect face in ID card and assign bounding box\n",
    "2. get detected face and separate it to the new image \n",
    "3. extract the image feature for next process (i.e image comparison)\n",
    "\n",
    "## Approach\n",
    "- resize image to uniform size \n",
    "- feed the image to mtcnn for face detection\n",
    "- applied bounding box\n",
    "- get detected face image\n",
    "- feature extraction for image comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import io\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db99408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "dataset_path = \".\\dataset\"\n",
    "example = os.path.join(dataset_path, \"vincent\") # feel free to change for specific photo that u want to test\n",
    "photos = glob.glob(example + \"\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(\\w+\\.\\w+)\"\n",
    "pattern2 = r\"_(\\w+)\\.\"\n",
    "dict_photo = dict.fromkeys([\"ktp_path\", \"selfie_path\"])\n",
    "for photo in photos:\n",
    "    match = re.search(pattern, photo)\n",
    "    type_photo = re.search(pattern2, match.group(0))\n",
    "    \n",
    "    if type_photo.group(1) == \"ktp\":\n",
    "        dict_photo[\"ktp_path\"] = photo\n",
    "    elif type_photo.group(1) == \"selfie\":\n",
    "        dict_photo[\"selfie_path\"] = photo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a4856",
   "metadata": {},
   "source": [
    "#### Face detector: MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b35e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open images and resize\n",
    "with open(dict_photo[\"ktp_path\"], mode='rb') as file:\n",
    "    file_bytes = file.read()\n",
    "img_pil = Image.open(io.BytesIO(file_bytes))\n",
    "img_pil = ImageOps.exif_transpose(img_pil)\n",
    "img_ktp = np.array(img_pil)\n",
    "img_ktp = cv2.resize(img_ktp, (1280, 1280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "with open(dict_photo[\"selfie_path\"], mode='rb') as file:\n",
    "    file_bytes = file.read()\n",
    "img_pil = Image.open(io.BytesIO(file_bytes))\n",
    "img_pil = ImageOps.exif_transpose(img_pil)\n",
    "img_selfie = np.array(img_pil)\n",
    "img_selfie = cv2.resize(img_selfie, (1280, 1280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "imgs = [img_ktp, img_selfie]\n",
    "\n",
    "# image detection(s)\n",
    "results = dict.fromkeys([\"ktp_result\", \"selfie_result\"])\n",
    "detector = MTCNN()\n",
    "results[\"ktp_result\"] = detector.detect_faces(img_ktp)\n",
    "results[\"selfie_result\"] = detector.detect_faces(img_selfie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b098e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img_ktp)\n",
    "plt.title(\"example id card\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"ktp_result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37695ec6",
   "metadata": {},
   "source": [
    "#### Get Results (detected face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store faces\n",
    "faces = list()\n",
    "detected_face = np.copy(img_ktp)\n",
    "x1, y1, width, height = results[\"ktp_result\"][0]['box']\n",
    "x1, y1 = abs(x1), abs(y1)\n",
    "x2, y2 = x1+width, y1+height\n",
    "\n",
    "# detected_face = cv2.rectangle(detected_face, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "detected_face = detected_face[y1:y2, x1:x2]\n",
    "detected_face = cv2.resize(detected_face, (1280, 1280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "faces.append(detected_face)\n",
    "\n",
    "# for selfie\n",
    "# pick face\n",
    "w = results[\"selfie_result\"][0]['box'][2]\n",
    "h = results[\"selfie_result\"][0]['box'][3]\n",
    "max_area = w * h\n",
    "i_result = 0\n",
    "for i in range(len(results[\"selfie_result\"])):\n",
    "    w = results[\"selfie_result\"][i]['box'][2]\n",
    "    h = results[\"selfie_result\"][i]['box'][3]\n",
    "    area = w * h\n",
    "    \n",
    "    if area > max_area:\n",
    "        max_area = area\n",
    "        i_result = i\n",
    "        \n",
    "# get detected face\n",
    "detected_face = np.copy(img_selfie)\n",
    "x1, y1, width, height = results[\"selfie_result\"][i_result]['box']\n",
    "x1, y1 = abs(x1), abs(y1)\n",
    "x2, y2 = x1+width, y1+height\n",
    "# detected_face = cv2.rectangle(detected_face, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "detected_face = detected_face[y1:y2, x1:x2]\n",
    "detected_face = cv2.resize(detected_face, (1280, 1280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "faces.append(detected_face)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(faces[1])\n",
    "plt.title(\"example id card\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cd2c2",
   "metadata": {},
   "source": [
    "#### Face comparison: ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface import ArcFace\n",
    "# sharpening\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "faces[0] = cv2.filter2D(src=faces[0], ddepth=-1, kernel=kernel)\n",
    "faces[1] = cv2.filter2D(src=faces[1], ddepth=-1, kernel=kernel)\n",
    "\n",
    "# ArcFace\n",
    "arc_face = ArcFace.ArcFace('./model/arcface_model')\n",
    "emb1 = arc_face.calc_emb(faces[0])\n",
    "emb2 = arc_face.calc_emb(faces[1])\n",
    "\n",
    "distance = arc_face.get_distance_embeddings(emb1, emb2)\n",
    "threshold = 1.6\n",
    "if distance > threshold:\n",
    "    print(f\"Not similar. Distance {distance}\")\n",
    "else:\n",
    "    print(f\"Similar. Distance {distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportstracker",
   "language": "python",
   "name": "sportstracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
